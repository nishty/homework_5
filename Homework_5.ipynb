{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Homework 5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishty/homework_5/blob/main/Homework_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq0XoVUIVNLC"
      },
      "source": [
        "# Homework 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aqF485OxR-U"
      },
      "source": [
        "**Before you start:** Read Chapter 8 Naive Bayes and Chapter 9 Decision Trees in the textbook.\n",
        "\n",
        "**Note:** Please enter the code along with your comments in the **TODO** section.\n",
        "\n",
        "Alternative solutions are always welcomed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IKYRqKtxR-N"
      },
      "source": [
        "### **Problem 1** (40 points)##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8fENJRPk7P7"
      },
      "source": [
        "In this problem, we need to build a Naive Bayes model to classify whether a movie review is positive or negative. \n",
        "\n",
        "The given data is a subset of [the IMDB movie review dataset](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews).\n",
        "\n",
        "This might be your first time working with text mining. Therefore, the basic pre-processing steps are given below. \n",
        "\n",
        "**You have two major tasks:**\n",
        "\n",
        "* Go through the code and get to know the purpose of each preprocessing step. Summarize what a preprocessing step does when required.\n",
        "* Build a multinomial Naive Bayes model to classify the reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8gmUJ3n8Mir",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "d8b193ec-5e9e-410c-bccd-fd5cdbfb25ba"
      },
      "source": [
        "# Import the dataset\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "file = files.upload()\n",
        "df = pd.read_csv(\"IMDB Dataset_subset.csv\")\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4ae19bbb-2d44-4ffb-8758-5fea364c3e23\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4ae19bbb-2d44-4ffb-8758-5fea364c3e23\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving IMDB Dataset_subset.csv to IMDB Dataset_subset (1).csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggt8c71U8MrD",
        "outputId": "599fa935-1022-41ae-e8a8-6a8f0a3d00ae"
      },
      "source": [
        "# Packages required for preprocessing #\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.stem import WordNetLemmatizer #for lemmatization\n",
        "import random\n",
        "import re #regular expression package\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMI-UZAQ9F-L"
      },
      "source": [
        "X = [row for row in df['review']] #list of reviews\n",
        "classes = df['sentiment'] #list of true classes"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4P3iseB_gIR"
      },
      "source": [
        "# Pre-process the data\n",
        "reviews = []\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "for review in range(0, len(X)):\n",
        "    # part 1\n",
        "    review = re.sub(r'[\\W_]', ' ', str(X[review])) \n",
        "    review = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', review) \n",
        "    review = re.sub(r'\\^[a-zA-Z]\\s+', ' ', review) \n",
        "    review = re.sub(r'\\s+', ' ', review, flags=re.I) \n",
        "    review = re.sub(r'^b\\s+', '', review) # if a review record is in bytes, the corresponding line will have a letter 'b' appended at the start)\n",
        "    review = review.lower()\n",
        "    review = re.sub(r'[0-9]+', '', review) \n",
        "\n",
        "    # part 2\n",
        "    review = review.split()\n",
        "    review = [lemmatizer.lemmatize(word) for word in review]\n",
        "    review = ' '.join(review)\n",
        "\n",
        "    reviews.append(review)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orhex-OXhkgV"
      },
      "source": [
        "\n",
        "**TODO 1**\n",
        "\n",
        "Explain the function that part 1 and part 2 achieve in the loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGnaXwAfBv8i"
      },
      "source": [
        "Part 1  is to clean the data by removing tabs, non alaphabets and other special charecters and numerics  , also replaces multiple spaces with single space. \n",
        "Converts all words to lower case.\n",
        "\n",
        "Part 2 converts sentances to a list of words and then replaces different variantes of the same word with one single replacement word.\n",
        "Then converts it back to a sentence "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXexNUV9CnXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a45fea-ce56-4e10-d176-bc1ad80ad893"
      },
      "source": [
        "# Continue with pre-processing\n",
        "vectorizer = CountVectorizer(stop_words = \"english\", max_df=0.7, min_df=5) \n",
        "texts = vectorizer.fit_transform(reviews).toarray()  \n",
        "vocab = vectorizer.vocabulary_ \n",
        "vocab = sorted(vocab.items(), key = lambda x: x[1])\n",
        "vocab = [v[0] for v in vocab]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000060000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000002000000000000000110000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100010000000000000000000000000000001000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000101000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000100010000000000000000000000000000000000000000000000000000001000001000000000001000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000030000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000010000000000000000000000000000000000000000000000001000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000001000000000000000000001000000000000000000000000000000000000000000000100000000000100000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000001000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000200000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000003000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001011000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000100000000000000000100000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000006000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000200000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001200000000000000000100000000000000000000000000000000000000000000000000000000000001010000000000000000000000000000000000000000000000000000000000000000100000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000002000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000010000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000400000000000000000000000000000000000003000000000000000000000000000000000000000000000000000000000000000001020000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000200000000000000000000100000000000000000000000000000000000000000000000000000000000000000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZPj-AWCC-YV"
      },
      "source": [
        "\n",
        "**TODO 2**\n",
        "\n",
        "What do \"texts\" and \"vocab\" represent? What is the relationship between them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOho20diDt6L"
      },
      "source": [
        "Generate counts from text using a vectorizer\n",
        "This performs our step of computing word counts\n",
        "Vocab is all unique words available in reviews \n",
        "\n",
        "Texts is a list of list of integers. Where is text[i] is a list of 0s and 1s, where text[i][j] = 0 means that review[i] doesn't contain the word vocab[j] and text[i][j] = 1 means that reviews[i] contains the word vocab[j]. Texts[i] represents the feature set of review[i]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkjhBNIlGFlu"
      },
      "source": [
        "**TODO 3**\n",
        "\n",
        "Partition the data into 80% training and 20% validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WeDE--MGMq5"
      },
      "source": [
        "X = texts\n",
        "y = df['sentiment'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 122 )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpGQxB2GGUzz"
      },
      "source": [
        "**TODO 4**\n",
        "\n",
        "Build a multinomial Naive Bayes model on the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJGgsv-JGvga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "defa5b57-ce1c-4816-8443-8049076fbff5"
      },
      "source": [
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train, [s for s in y_train])\n",
        "predictions = mnb.predict(X_test)\n",
        "\n",
        "pred_text = \"\"\n",
        "for p in predictions:\n",
        "    if p == \"positive\":\n",
        "      pred_text += \" p\"\n",
        "    else:\n",
        "      pred_text += \" n\"\n",
        "\n",
        "actual_text = \"\"\n",
        "for a in y_test:\n",
        "    if a == \"positive\":\n",
        "      actual_text += \" p\"\n",
        "    else:\n",
        "      actual_text += \" n\"\n",
        "\n",
        "print(pred_text)\n",
        "print(\"\\n\")\n",
        "print(actual_text)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " p p n p n p n p p n p n n p n p n p p p n n n n n p n p p n n n n n n n p p p n n p p n n p n n n n p n p p n n p n n n n p n p p p p n p p n p n n p p p n p p p p n n p n p n n p n p n p n n n p n n p n p n p p n p p p p p n n p n n n p n p n n p p n p p n n p p p p n n p p n p n n p p p p p n n p n n p n n p p n p p n n p n n n n n n n p n n n p p n p p p n p n n n n n n n n n p p n n n p p n p p n n n n n n n p n n n n p n n n n n p n n n n n p n p p p p p n p p p n p n n n n n n n n p p n n n n n n n p p p p n n p p p n n n n p n p p p n n n n p n n n n p p p n n n p n p n n n n p n n n p n n p p p p p n p p n p n n p p n n p p p p p p p n p p p n n n n n n p p n n n p p n n p p p p n n n p p p p p n n n n n n n n n p p n n p n n p p p n p n n n p n p n n n p n p p p n p p n p p n p p n n p n n n p p n n p n n p p n p p p p p p p n n n p n p n n p p p n n p p n n n n n n p p p p p p p n p p p n n n n n n p p n n n p n p p n p n p p n p p p n p n n n n p p p n n p p p p n p p n n n p n n n p n p p p p p n n n p n p n p p n n n n n n n p p n n n n n n n n p p p p n n n n p p n p n p n p n n n p n p n n n n p p p n p n n p p p p n p p p p n n p n n p p n n p n n n n n p p n n n n n p n n n p p p n p p n p p n n p n n n n p p p n p n p n n p p p n p p n p n p n n n p n n n p n p p n n n n n n n p p n n n p n n n p n n p p n n p n p n n p n p p n p n n n p p n n n n n n n n n p n p p p p p n n p n p p n p n n n p p p p n p n p p n p p n p n n n n p n n p n n p p n n n p n n p n n n n p p n n p p n n n p n p n n n p n n n p n n n p n n n n n p p n n p p p n p n n p p n n n p\n",
            "\n",
            "\n",
            " n p n p n n n p p n p n n p p p n p p p n n n n n p p n p n n p p n n n p p p n p n p n n n p p p n n n p n n n p n n p n n n p p p p p p n n p n n p p p n p p n p n p n n p n p p n p n p n n n p n p p n n p p p n p p p p p n n p n n n n n p n p p p n p p n n p p p p n p p p p p n p p p p p p p n p n n p n n n p n p p p n n n n n n n n n n n n n n p n p p p n p n n n n n n n n n p p n n n n p n p p p p n n n n n p n p n n p n n p n n p n n p n n p n p n p p p n p p n n p n n n n p n n n p p n n n p p n n n p p p n n p p p n n n n p n p p p n n n n p n n n p p p p n p n p n p n n n n p n n n p n p p p p p p n p p n p n p p p n p p n p p n p p n n p p n n n p n n p p n n n p p n n p p n p p n p p p n p p n n p n p n n n n p p n p p n p p p p n p n n n p n n n n n p p p p p n p p n p p n p p n n p n p p p p p n n n n n p n p n p p p p p n n n p n p n n p p n n n p p n n p p n n p n p p p n n n p p p n n n n n p p p n p n p n p p n p n p p n n n n n p n n p n n p n n n p p p p n p n n n p p p n n p n p n n p p n n p p p p n p p n n p n n n n n p n n n n n p p n n p p n n n n n n p n n n p n p n n n p n p n n n p p p p p p n n p p p p n p p p p n n p n n p p n n p p n n n n p n n n n p p p n n n p p p n p p n p p n n p n n n n p n p p n n p n p p p p p p p n n n p n n n p n n n p p p p n n n n p n p n p n n n p n n n p n n p n n n p p p n n p n p p n n p n n p p p n n n n p n n n p p p n p p p n n p n n p p p n n n p p p p p p n p p n p p n p n n p p p n p n n n p n p n p p n n p n p n n p n n n p n n n n p n n n n n p p p p p n p n p n n p p n p n n n p p p n n n n p n n p n p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyypSMm_GzGb"
      },
      "source": [
        "**Hint:** [Multinomial Naive Bayes with sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXBPDB_KtVe5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfIyk3vMGww0"
      },
      "source": [
        "**TODO 5**\n",
        "\n",
        "Evaluate the model performance with the training and validation set. Comment on the model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5TyEr9pHJGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c4c55e-59f6-48cb-d786-12aa715a1501"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(predictions, y_test)*100"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQy7IX2xHK1-"
      },
      "source": [
        "**Hint:** [Classification report with sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIRgUPM8HiOK"
      },
      "source": [
        "**If you are interested (this part is not graded):**\n",
        "\n",
        "Explore one or two records that were misclassified. Check the original text, vectorized text, and comment on the possible reason why the record got misclassified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REELGHe8IFcZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUezdM7RpDDk"
      },
      "source": [
        "### **Problem 2** (40 points)##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJty4hSgo7ER"
      },
      "source": [
        "The wine dataset is the result of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. (For illustration simplicity purpose, only 2 classes, 0 and 1, will be included for the classification task.) The analysis determined the quantities of 13 constituents found in each of the three types of wines.\n",
        "\n",
        "The objective is to classify the wines into class 0 or 1 using the 13 given attributes and a decision tree classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3LWlHCfkOGN"
      },
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "\n",
        "# load the wine dataset \n",
        "wine = datasets.load_wine()\n",
        "print(wine.DESCR)\n",
        "\n",
        "# convert the data into dataframe format\n",
        "X = pd.DataFrame(wine['data'], columns = wine['feature_names'])\n",
        "y = wine['target']\n",
        "\n",
        "# only consider wine class 0 and 1\n",
        "X = X.loc[0:129, :]\n",
        "y = y[0:130]\n",
        "\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR8h9hqbo7EY"
      },
      "source": [
        "**TODO 1**\n",
        "\n",
        "Partition the data into 70% training and 30% validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auq1CX17dHYJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsEYkioxstdx"
      },
      "source": [
        "**TODO 2**\n",
        "\n",
        "Fit a decision tree classifier on the training set with no pruning.\n",
        "\n",
        "Plot the tree with the following requirements:\n",
        "\n",
        "\n",
        "*   The node with splitting rule should contain variable name instead of variable index.\n",
        "*   Pick the appropriate information to present in the node. The node should be of appropriate size so the information is clear for viewing.\n",
        "*   The node should be colored.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ADHp1lkejI5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLqT19n6t9Rc"
      },
      "source": [
        "**Hint:** [Decision tree classifier with sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l6qSMhsuUPi"
      },
      "source": [
        "**TODO 3**\n",
        "\n",
        "Prune the tree with cost complexity. What is the best ccp value? Use visualization to back up your decision. \n",
        "\n",
        "Plot the pruned tree in the same manner as TODO 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHl4dddCuq68"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQMsxlbluuNn"
      },
      "source": [
        "**Hint:** [Minimal cost complexity pruning](https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning)\n",
        "\n",
        "[Post pruning decision trees with cost complexity with sklearn](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgA3MnRn865U"
      },
      "source": [
        "### **Problem 3** (20 points)##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8tBRqNfBVl7"
      },
      "source": [
        "Answer the following short answer questions and back up your answer with explanations and/or examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sns4_PKb_g7s"
      },
      "source": [
        "**TODO 1**\n",
        "\n",
        "What type of input and response variables can a Naive Bayes classifier handle? \n",
        "\n",
        "What kind of dataset is ideal for applying the Naive Bayes classifier?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1HSqy7TBjKQ"
      },
      "source": [
        "Naive Bayes can only handle categorical values\n",
        "\n",
        "Data sets that are ideal for Naive Bayes classifier are \n",
        "high-dimensional data sets such as text classification, email spam detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc0pZA4SBoWX"
      },
      "source": [
        "**TODO 2**\n",
        "\n",
        "What are the pros and cons of a Naive Bayes classifier comparing to other classfiers we learnt in class?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BCKlEo-BoWY"
      },
      "source": [
        "Pros:\n",
        "Can be used on Large Data sets\n",
        "Good to work on Categorical datasets compared to other classifiers\n",
        "Simple to undersand and implemt and not computationally expensive\n",
        "When assumption of independent predictors holds true, a Naive Bayes classifier performs better as compared to other models.\n",
        "\n",
        "Cons:\n",
        "Requires Large amount of data\n",
        "It can be an issue when predictor is not present in the training data\n",
        "Probability rankings maybe more accurate than actual probability, hence accuray may be lesser for applications requiring probabilities.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-EuP4O5C0d4"
      },
      "source": [
        "**TODO 3**\n",
        "\n",
        "What type of input and response variables can a decision tree model handle? \n",
        "\n",
        "What kind of dataset is ideal for applying the decision tree model?\n",
        "\n",
        "Discuss the classification tree and regression tree separately if necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD9Z0CyxC0eE"
      },
      "source": [
        "Decision Trees are helpful for both categorical and continuous input / output variables\n",
        "Regression Tree is used with continious variables\n",
        "\n",
        "Decision trees are best for handling  non-linear data sets effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpAGgtS1C0eF"
      },
      "source": [
        "**TODO 4**\n",
        "\n",
        "What are the pros and cons of a decision tree model comparing to other models we learnt in class?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVjcaQReC0eF"
      },
      "source": [
        "Pros :\n",
        "\n",
        "Easy to understand\n",
        "Missing values do not affect process of building a decision tree\n",
        "Does not require normalization of data\n",
        "Does not require scaling of data\n",
        "Produces rules easy to identify and interpret\n",
        "\n",
        "Cons:\n",
        "\n",
        "A small change in the data can cause a big change to the structure of the decision tree , hence causing instability.\n",
        "Requires higher time to train the model\n",
        "More expensive computationally \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArHlEe1GDTjK"
      },
      "source": [
        "**TODO 5**\n",
        "\n",
        "Between the Naive Bayes classifier and the classification tree, which one is more prone to overfitting the training data? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkdXSAMhDTjW"
      },
      "source": [
        "Classification tree is more prone to overfitting the training data.\n",
        "A highly overfitted tree  gives highly accurate output on training data, but low accurate output on test data."
      ]
    }
  ]
}